{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RlZu1rxMt77N"
   },
   "source": [
    "# For Training and Loading the Pretrained Model on a Fresh Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gkwITU5hFTpM"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.pyplot import imread\n",
    "from keras.layers import Input\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1665321501386,
     "user": {
      "displayName": "Raj Shekhar Vaghela",
      "userId": "17386515312137102891"
     },
     "user_tz": -330
    },
    "id": "ZyAYm1hIJ5AF",
    "outputId": "74d18cd1-7be9-426c-b6fd-aa3811cae6f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.8.2\n",
      "Hub version: 0.12.0\n",
      "GPU available\n"
     ]
    }
   ],
   "source": [
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"Hub version:\", hub.__version__)\n",
    "\n",
    "# Check for GPU\n",
    "print(\"GPU\", \"available\" if tf.config.list_physical_devices(\"GPU\") else \"not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tO79ce92J6hH"
   },
   "outputs": [],
   "source": [
    "train_labels_csv = pd.read_csv(\"drive/MyDrive/Datathon/train_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fDXtkZfjKF-H"
   },
   "outputs": [],
   "source": [
    "labels = train_labels_csv[\"label\"].to_numpy() # convert labels column to NumPy array (from Training Dataset)\n",
    "# Finding the unique labels\n",
    "unique_labels = np.unique(labels)\n",
    "# Turn every label into a boolean array\n",
    "boolean_labels = [label == np.array(unique_labels) for label in labels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2yeVv3pMKVWM"
   },
   "outputs": [],
   "source": [
    "# Create pathnames from image ID's\n",
    "train_path = \"drive/MyDrive/Datathon/train/train/\"\n",
    "filenames = [train_path + str(fname) + \".jpeg\" for fname in train_labels_csv[\"id\"]]      # Fetching training files' IDs from train_labels_csv\n",
    "\n",
    "val_path = \"drive/MyDrive/Datathon/validation/validation/\"\n",
    "val_filenames = [val_path + str(fname) for fname in os.listdir(val_path)]       # Fetching Validation files' IDs from the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jHQJsrvo5ndK"
   },
   "outputs": [],
   "source": [
    "# Setup X & y variables\n",
    "X = filenames\n",
    "y = boolean_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dGGhJS5FKbVl"
   },
   "outputs": [],
   "source": [
    "# Define image size\n",
    "IMG_SIZE = 224\n",
    "\n",
    "def process_image(image_path):\n",
    "  \"\"\"\n",
    "  Takes an image file path and turns it into a Tensor.\n",
    "  \"\"\"\n",
    "  # Read in image file\n",
    "  image = tf.io.read_file(image_path)\n",
    "  # Turn the jpeg image into numerical Tensor with 3 colour channels (Red, Green, Blue)\n",
    "  image = tf.image.decode_jpeg(image, channels=3)\n",
    "  # Convert the colour channel values from 0-225 values to 0-1 values\n",
    "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "  # Resize the image to our desired size (224, 244)\n",
    "  image = tf.image.resize(image, size=[IMG_SIZE, IMG_SIZE])\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NJEGS3j_Kk4N"
   },
   "outputs": [],
   "source": [
    "# Create a simple function to return a tuple (image, label)\n",
    "def get_image_label(image_path, label):\n",
    "  \"\"\"\n",
    "  Takes an image file path name and the associated label,\n",
    "  processes the image and returns a tuple of (image, label).\n",
    "  \"\"\"\n",
    "  image = process_image(image_path)\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7hqzeHeIKmc9"
   },
   "outputs": [],
   "source": [
    "# Define the batch size, 32 is a good default\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Create a function to turn data into batches\n",
    "def create_data_batches(x, y=None, batch_size=BATCH_SIZE, valid_data=False, test_data=False):\n",
    "  \"\"\"\n",
    "  Creates batches of data out of image (x) and label (y) pairs.\n",
    "  Shuffles the data if it's training data but doesn't shuffle it if it's validation data.\n",
    "  Also accepts test data as input (no labels).\n",
    "  \"\"\"\n",
    "  # If the data is a test dataset, we probably don't have labels\n",
    "  if test_data:\n",
    "    print(\"Creating test data batches...\")\n",
    "    data = tf.data.Dataset.from_tensor_slices((tf.constant(x))) # only filepaths\n",
    "    data_batch = data.map(process_image).batch(BATCH_SIZE)\n",
    "    return data_batch\n",
    "  \n",
    "  # If the data if a valid dataset, we don't need to shuffle it\n",
    "  elif valid_data:\n",
    "    print(\"Creating validation data batches...\")\n",
    "    data = tf.data.Dataset.from_tensor_slices((tf.constant(x), # filepaths\n",
    "                                               tf.constant(y))) # labels\n",
    "    data_batch = data.map(get_image_label).batch(BATCH_SIZE)\n",
    "    return data_batch\n",
    "\n",
    "  else:\n",
    "    # If the data is a training dataset, we shuffle it\n",
    "    print(\"Creating training data batches...\")\n",
    "    # Turn filepaths and labels into Tensors\n",
    "    data = tf.data.Dataset.from_tensor_slices((tf.constant(x), # filepaths\n",
    "                                              tf.constant(y))) # labels\n",
    "    \n",
    "\n",
    "    # Create (image, label) tuples (this also turns the image path into a preprocessed image)\n",
    "    data = data.map(get_image_label)\n",
    "\n",
    "    # Turn the data into batches\n",
    "    data_batch = data.batch(BATCH_SIZE)\n",
    "  return data_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 766,
     "status": "ok",
     "timestamp": 1665321587982,
     "user": {
      "displayName": "Raj Shekhar Vaghela",
      "userId": "17386515312137102891"
     },
     "user_tz": -330
    },
    "id": "E95RHTk_Kn3d",
    "outputId": "fbb65f39-e3e0-4d95-a230-1f54df4f556b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training data batches...\n"
     ]
    }
   ],
   "source": [
    "# Turn full training data in a data batch\n",
    "full_data = create_data_batches(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J4G6G1QOKo6N"
   },
   "outputs": [],
   "source": [
    "# Setup input shape to the model\n",
    "INPUT_SHAPE = [None, IMG_SIZE, IMG_SIZE, 3] # batch, height, width, colour channels\n",
    "\n",
    "# Setup output shape of the model\n",
    "OUTPUT_SHAPE = len(unique_labels) # number of unique labels\n",
    "\n",
    "# Setup model URL from TensorFlow Hub\n",
    "MODEL_URL = \"https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TYIutERlKrIH"
   },
   "outputs": [],
   "source": [
    "# we will build the model using the Keras API\n",
    "\n",
    "def create_model(input_shape=INPUT_SHAPE, output_shape=OUTPUT_SHAPE, model_url=MODEL_URL):\n",
    "  print(\"Building the model with:\", MODEL_URL)\n",
    "\n",
    "  # Setup the model layers\n",
    "  model = tf.keras.Sequential([\n",
    "    hub.KerasLayer(MODEL_URL), # Layer 1 (input layer)\n",
    "    tf.keras.layers.Dense(units=OUTPUT_SHAPE, \n",
    "                          activation=\"softmax\") # Layer 2 (output layer). Softmax will predict the probabilities for each class for each image\n",
    "  ])\n",
    "\n",
    "  # Compile the model\n",
    "  model.compile(\n",
    "      loss=tf.keras.losses.CategoricalCrossentropy(), # Our model wants to reduce this (how wrong its guesses are)\n",
    "      optimizer=tf.keras.optimizers.Adam(), # An optimizer helping our model how to improve its guesses\n",
    "      metrics=[\"accuracy\"] # We'd like this to go up\n",
    "  )\n",
    "\n",
    "  # Build the model\n",
    "  model.build(INPUT_SHAPE) # Let the model know what kind of inputs it'll be getting\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQ5fZFDQ4gw5"
   },
   "source": [
    "## Creating the Model 2 for Full data Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2484,
     "status": "ok",
     "timestamp": 1665227158533,
     "user": {
      "displayName": "Raj Shekhar Vaghela",
      "userId": "17386515312137102891"
     },
     "user_tz": -330
    },
    "id": "D0Mvji6nKscJ",
    "outputId": "8cb71b26-ecf6-4116-9312-68c793861208"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the model with: https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer_2 (KerasLayer)  (None, 1001)              3540265   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                16032     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,556,297\n",
      "Trainable params: 16,032\n",
      "Non-trainable params: 3,540,265\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a new model for training on the full dataset\n",
    "full_model2 = create_model()\n",
    "full_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WNLYMgjtuhqA"
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "import datetime\n",
    "\n",
    "# Create a function to build a TensorBoard callback\n",
    "def create_tensorboard_callback():\n",
    "  # Create a log directory for storing TensorBoard logs\n",
    "  logdir = os.path.join(\"drive/MyDrive/Datathon/logs\",\n",
    "                        # Make it so the logs get tracked whenever we run an experiment\n",
    "                        datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "  return tf.keras.callbacks.TensorBoard(logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fnhQKzX8KuM8"
   },
   "outputs": [],
   "source": [
    "# Create full model callbacks\n",
    "\n",
    "# TensorBoard callback\n",
    "full_model_tensorboard = create_tensorboard_callback()\n",
    "\n",
    "# Early stopping callback\n",
    "# Note: No validation set when training on all the data, so we monitor only training accuracy\n",
    "full_model_early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"accuracy\",\n",
    "                                                             patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5HVZ9qF5MrvZ"
   },
   "outputs": [],
   "source": [
    "def save_model(model, suffix=None):\n",
    "  \"\"\"\n",
    "  Saves a given model in a models directory and appends a suffix (str)\n",
    "  for clarity and reuse.\n",
    "  \"\"\"\n",
    "  # Create model directory with current time\n",
    "  modeldir = os.path.join(\"drive/MyDrive/Datathon/models\",\n",
    "                          datetime.datetime.now().strftime(\"%Y%m%d-%H%M%s\"))\n",
    "  model_path = modeldir + \"-\" + suffix + \".h5\" # save format of model\n",
    "  print(f\"Saving model to: {model_path}...\")\n",
    "  model.save(model_path)\n",
    "  return model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y8u-65LpMt0w"
   },
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "  \"\"\"\n",
    "  Loads a saved model from a specified path.\n",
    "  \"\"\"\n",
    "  print(f\"Loading saved model from: {model_path}\")\n",
    "  model = tf.keras.models.load_model(model_path,\n",
    "                                     custom_objects={\"KerasLayer\":hub.KerasLayer})\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13745801,
     "status": "ok",
     "timestamp": 1665240904327,
     "user": {
      "displayName": "Raj Shekhar Vaghela",
      "userId": "17386515312137102891"
     },
     "user_tz": -330
    },
    "id": "02CIR-wyQ8sr",
    "outputId": "91179101-1ff5-4b71-c5bb-89c124160618"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "500/500 [==============================] - 5244s 10s/step - loss: 1.6419 - accuracy: 0.4993\n",
      "Epoch 2/60\n",
      "500/500 [==============================] - 109s 218ms/step - loss: 1.3858 - accuracy: 0.5766\n",
      "Epoch 3/60\n",
      "500/500 [==============================] - 106s 212ms/step - loss: 1.3135 - accuracy: 0.5981\n",
      "Epoch 4/60\n",
      "500/500 [==============================] - 106s 212ms/step - loss: 1.2690 - accuracy: 0.6124\n",
      "Epoch 5/60\n",
      "500/500 [==============================] - 106s 212ms/step - loss: 1.2368 - accuracy: 0.6211\n",
      "Epoch 6/60\n",
      "500/500 [==============================] - 107s 214ms/step - loss: 1.2117 - accuracy: 0.6278\n",
      "Epoch 7/60\n",
      "500/500 [==============================] - 106s 212ms/step - loss: 1.1910 - accuracy: 0.6332\n",
      "Epoch 8/60\n",
      "500/500 [==============================] - 106s 213ms/step - loss: 1.1736 - accuracy: 0.6389\n",
      "Epoch 9/60\n",
      "500/500 [==============================] - 108s 216ms/step - loss: 1.1585 - accuracy: 0.6440\n",
      "Epoch 10/60\n",
      "500/500 [==============================] - 108s 215ms/step - loss: 1.1452 - accuracy: 0.6478\n",
      "Epoch 11/60\n",
      "500/500 [==============================] - 107s 213ms/step - loss: 1.1333 - accuracy: 0.6513\n",
      "Epoch 12/60\n",
      "500/500 [==============================] - 108s 216ms/step - loss: 1.1225 - accuracy: 0.6539\n",
      "Epoch 13/60\n",
      "500/500 [==============================] - 106s 213ms/step - loss: 1.1127 - accuracy: 0.6571\n",
      "Epoch 14/60\n",
      "500/500 [==============================] - 107s 213ms/step - loss: 1.1037 - accuracy: 0.6601\n",
      "Epoch 15/60\n",
      "500/500 [==============================] - 106s 211ms/step - loss: 1.0953 - accuracy: 0.6622\n",
      "Epoch 16/60\n",
      "500/500 [==============================] - 104s 209ms/step - loss: 1.0875 - accuracy: 0.6647\n",
      "Epoch 17/60\n",
      "500/500 [==============================] - 104s 208ms/step - loss: 1.0801 - accuracy: 0.6672\n",
      "Epoch 18/60\n",
      "500/500 [==============================] - 104s 208ms/step - loss: 1.0733 - accuracy: 0.6696\n",
      "Epoch 19/60\n",
      "500/500 [==============================] - 104s 208ms/step - loss: 1.0668 - accuracy: 0.6713\n",
      "Epoch 20/60\n",
      "500/500 [==============================] - 104s 208ms/step - loss: 1.0606 - accuracy: 0.6725\n",
      "Epoch 21/60\n",
      "500/500 [==============================] - 104s 207ms/step - loss: 1.0547 - accuracy: 0.6738\n",
      "Epoch 22/60\n",
      "500/500 [==============================] - 103s 206ms/step - loss: 1.0492 - accuracy: 0.6759\n",
      "Epoch 23/60\n",
      "500/500 [==============================] - 104s 208ms/step - loss: 1.0438 - accuracy: 0.6772\n",
      "Epoch 24/60\n",
      "500/500 [==============================] - 104s 208ms/step - loss: 1.0387 - accuracy: 0.6782\n",
      "Epoch 25/60\n",
      "500/500 [==============================] - 104s 207ms/step - loss: 1.0339 - accuracy: 0.6794\n",
      "Epoch 26/60\n",
      "500/500 [==============================] - 104s 209ms/step - loss: 1.0292 - accuracy: 0.6816\n",
      "Epoch 27/60\n",
      "500/500 [==============================] - 104s 208ms/step - loss: 1.0246 - accuracy: 0.6829\n",
      "Epoch 28/60\n",
      "500/500 [==============================] - 105s 209ms/step - loss: 1.0203 - accuracy: 0.6842\n",
      "Epoch 29/60\n",
      "500/500 [==============================] - 103s 207ms/step - loss: 1.0161 - accuracy: 0.6858\n",
      "Epoch 30/60\n",
      "500/500 [==============================] - 104s 209ms/step - loss: 1.0120 - accuracy: 0.6864\n",
      "Epoch 31/60\n",
      "500/500 [==============================] - 106s 211ms/step - loss: 1.0081 - accuracy: 0.6873\n",
      "Epoch 32/60\n",
      "500/500 [==============================] - 106s 211ms/step - loss: 1.0043 - accuracy: 0.6883\n",
      "Epoch 33/60\n",
      "500/500 [==============================] - 105s 210ms/step - loss: 1.0006 - accuracy: 0.6900\n",
      "Epoch 34/60\n",
      "500/500 [==============================] - 106s 212ms/step - loss: 0.9970 - accuracy: 0.6913\n",
      "Epoch 35/60\n",
      "500/500 [==============================] - 106s 211ms/step - loss: 0.9936 - accuracy: 0.6927\n",
      "Epoch 36/60\n",
      "500/500 [==============================] - 106s 212ms/step - loss: 0.9902 - accuracy: 0.6932\n",
      "Epoch 37/60\n",
      "500/500 [==============================] - 106s 211ms/step - loss: 0.9869 - accuracy: 0.6945\n",
      "Epoch 38/60\n",
      "500/500 [==============================] - 105s 210ms/step - loss: 0.9837 - accuracy: 0.6952\n",
      "Epoch 39/60\n",
      "500/500 [==============================] - 105s 210ms/step - loss: 0.9806 - accuracy: 0.6956\n",
      "Epoch 40/60\n",
      "500/500 [==============================] - 105s 210ms/step - loss: 0.9776 - accuracy: 0.6963\n",
      "Epoch 41/60\n",
      "500/500 [==============================] - 722s 1s/step - loss: 0.9746 - accuracy: 0.6969\n",
      "Epoch 42/60\n",
      "500/500 [==============================] - 105s 210ms/step - loss: 0.9717 - accuracy: 0.6971\n",
      "Epoch 43/60\n",
      "500/500 [==============================] - 105s 210ms/step - loss: 0.9689 - accuracy: 0.6984\n",
      "Epoch 44/60\n",
      "500/500 [==============================] - 105s 211ms/step - loss: 0.9662 - accuracy: 0.6995\n",
      "Epoch 45/60\n",
      "500/500 [==============================] - 105s 209ms/step - loss: 0.9635 - accuracy: 0.7002\n",
      "Epoch 46/60\n",
      "500/500 [==============================] - 105s 209ms/step - loss: 0.9609 - accuracy: 0.7006\n",
      "Epoch 47/60\n",
      "500/500 [==============================] - 105s 210ms/step - loss: 0.9583 - accuracy: 0.7013\n",
      "Epoch 48/60\n",
      "500/500 [==============================] - 106s 211ms/step - loss: 0.9558 - accuracy: 0.7016\n",
      "Epoch 49/60\n",
      "500/500 [==============================] - 105s 210ms/step - loss: 0.9533 - accuracy: 0.7028\n",
      "Epoch 50/60\n",
      "500/500 [==============================] - 106s 211ms/step - loss: 0.9509 - accuracy: 0.7037\n",
      "Epoch 51/60\n",
      "500/500 [==============================] - 105s 210ms/step - loss: 0.9485 - accuracy: 0.7048\n",
      "Epoch 52/60\n",
      "500/500 [==============================] - 106s 211ms/step - loss: 0.9462 - accuracy: 0.7059\n",
      "Epoch 53/60\n",
      "500/500 [==============================] - 105s 211ms/step - loss: 0.9439 - accuracy: 0.7064\n",
      "Epoch 54/60\n",
      "500/500 [==============================] - 105s 210ms/step - loss: 0.9417 - accuracy: 0.7070\n",
      "Epoch 55/60\n",
      "500/500 [==============================] - 106s 213ms/step - loss: 0.9395 - accuracy: 0.7078\n",
      "Epoch 56/60\n",
      "500/500 [==============================] - 106s 213ms/step - loss: 0.9374 - accuracy: 0.7084\n",
      "Epoch 57/60\n",
      "500/500 [==============================] - 106s 211ms/step - loss: 0.9353 - accuracy: 0.7088\n",
      "Epoch 58/60\n",
      "500/500 [==============================] - 105s 211ms/step - loss: 0.9332 - accuracy: 0.7093\n",
      "Epoch 59/60\n",
      "500/500 [==============================] - 107s 214ms/step - loss: 0.9311 - accuracy: 0.7101\n",
      "Epoch 60/60\n",
      "500/500 [==============================] - 106s 212ms/step - loss: 0.9291 - accuracy: 0.7109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fea1622a990>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the full model to the full training data\n",
    "full_model2.fit(x=full_data,\n",
    "               epochs=NUM_EPOCHS,\n",
    "               callbacks=[full_model_tensorboard, \n",
    "                          full_model_early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "executionInfo": {
     "elapsed": 658,
     "status": "ok",
     "timestamp": 1665240924282,
     "user": {
      "displayName": "Raj Shekhar Vaghela",
      "userId": "17386515312137102891"
     },
     "user_tz": -330
    },
    "id": "HI4SVAQaMwXV",
    "outputId": "f08e299c-d0cf-4fa8-e761-831ff2682236"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to: drive/MyDrive/Datathon/models/20221008-14551665240924-full-model-2-Adam.h5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'drive/MyDrive/Datathon/models/20221008-14551665240924-full-model-2-Adam.h5'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save our model trained on 4000 images from the Training Dataset\n",
    "save_model(full_model2, suffix=\"full-model-2-Adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6206,
     "status": "ok",
     "timestamp": 1665255427119,
     "user": {
      "displayName": "Raj Shekhar Vaghela",
      "userId": "17386515312137102891"
     },
     "user_tz": -330
    },
    "id": "CNmB7eYIMywr",
    "outputId": "f725a08a-91fc-469a-e55f-c475aabacb5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved model from: drive/MyDrive/Datathon/models/20221008-14551665240924-full-model-2-Adam.h5\n"
     ]
    }
   ],
   "source": [
    "# Load our model trained on 1000 images\n",
    "loaded_model = load_model('drive/MyDrive/Datathon/models/20221008-14551665240924-full-model-2-Adam.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 432,
     "status": "ok",
     "timestamp": 1665255884385,
     "user": {
      "displayName": "Raj Shekhar Vaghela",
      "userId": "17386515312137102891"
     },
     "user_tz": -330
    },
    "id": "VUgnLfpV9Wme",
    "outputId": "7739d715-5b9e-4e8c-ccd8-fd9611ea9087"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating validation data batches...\n"
     ]
    }
   ],
   "source": [
    "X_val = X[:500]\n",
    "y_val = y[:500]\n",
    "val_data = create_data_batches(X_val, y_val, valid_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 81302,
     "status": "ok",
     "timestamp": 1665255966656,
     "user": {
      "displayName": "Raj Shekhar Vaghela",
      "userId": "17386515312137102891"
     },
     "user_tz": -330
    },
    "id": "DgffU6nG94Mm",
    "outputId": "c4216aef-78cb-418b-b3d9-ede0a44b431f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 81s 5s/step - loss: 0.9254 - accuracy: 0.7220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9254278540611267, 0.722000002861023]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the loaded model\n",
    "loaded_model.evaluate(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bfQwWQmi-9ee"
   },
   "outputs": [],
   "source": [
    "# Turn prediction probabilities into their labels (Document Types)\n",
    "def get_pred_label(prediction_probabilities):\n",
    "  \"\"\"\n",
    "  Turns an array of prediction probabilities into a label.\n",
    "  \"\"\"\n",
    "  return unique_labels[np.argmax(prediction_probabilities)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jh7rKKQFGefG"
   },
   "outputs": [],
   "source": [
    "model_path = \"drive/MyDrive/Datathon/models/20221007-08281665131319-full-trained-adam.h5\" \n",
    "data_path = \"drive/MyDrive/Datathon/validation/validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7U88mvoxGc6q"
   },
   "outputs": [],
   "source": [
    "# Function to test the validation data stored in 'data_path' with the model stored in 'model_path'\n",
    "# here, model_path = \"drive/MyDrive/Datathon/models/20221007-08281665131319-full-trained-adam.h5\" \n",
    "#       data_path = \"drive/MyDrive/Datathon/validation/validation\"\n",
    "\n",
    "def test(model_path, data_path):\n",
    "  # Load the fully trained model\n",
    "  loaded_full_model = load_model(model_path)\n",
    "\n",
    "  # Load validation image filenames\n",
    "  val_path = data_path\n",
    "  val_filenames = [val_path + fname for fname in os.listdir(val_path)]\n",
    "\n",
    "  # Getting the list of validation set IDs\n",
    "  val_id = [id for id in os.listdir(val_path)]\n",
    "  val_ids = []\n",
    "  for item in val_id:\n",
    "    val_ids.append(int(item.split(\".\")[0]))\n",
    "  \n",
    "  # Create validation data batch so as to turn it into tensors and then fit it in our model\n",
    "  val_data = create_data_batches(val_filenames, test_data=True) \n",
    "\n",
    "  # Make predictions on the validation data \n",
    "  predictions = loaded_full_model.predict(val_data, verbose=1) \n",
    "  \n",
    "  # Getting the predicted labels in array val_pred_labels[]\n",
    "  val_pred_labels = []\n",
    "  for i in range(len(val_ids)):\n",
    "    val_pred_labels.append(get_pred_label(predictions[i]))\n",
    "  \n",
    "  # Fitting the data into Pandas dataframe\n",
    "  data = []\n",
    "  for i in range(len(val_ids)):\n",
    "    data.append((val_ids[i], val_pred_labels[i]))\n",
    "  df = pd.DataFrame(data, columns=['id','label'])\n",
    "\n",
    "  # Saving the predicted labels on validation set images in CSV\n",
    "  # Saving the predictions to predicted_label.csv file and saving it inside the datathon folder in GDrive\n",
    "  # df.to_csv(r'drive/MyDrive/Datathon/predicted_label2.csv', index=False) \n",
    "  df.to_csv(r'drive/MyDrive/Datathon/predicted_label.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mhmWn7z10bh3"
   },
   "outputs": [],
   "source": [
    "test(model_path, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 450,
     "status": "ok",
     "timestamp": 1665258323896,
     "user": {
      "displayName": "Raj Shekhar Vaghela",
      "userId": "17386515312137102891"
     },
     "user_tz": -330
    },
    "id": "W48rem9SGj9L",
    "outputId": "e72f0ea5-b8a3-4262-c5c8-1faaf7ca9796"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-88e9534d-e10a-4871-aada-bf8b99959287\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17801</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17802</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17803</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17804</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17805</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>18696</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>18697</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>18698</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>18699</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>18700</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows × 2 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-88e9534d-e10a-4871-aada-bf8b99959287')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-88e9534d-e10a-4871-aada-bf8b99959287 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-88e9534d-e10a-4871-aada-bf8b99959287');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "        id  label\n",
       "0    17801      4\n",
       "1    17802      6\n",
       "2    17803      4\n",
       "3    17804      8\n",
       "4    17805      3\n",
       "..     ...    ...\n",
       "895  18696      1\n",
       "896  18697     12\n",
       "897  18698      8\n",
       "898  18699     14\n",
       "899  18700      4\n",
       "\n",
       "[900 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= pd.read_csv('drive/MyDrive/Datathon/predicted_label.csv')\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
